{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Reviews on Olist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŽ¯ Now that you are familiar with NLP, let's analyze the reviews of Olist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ Run the following cell to load the reviews dataset and install `unidecode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_id</th>\n",
       "      <th>length_review</th>\n",
       "      <th>review_score</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7bc2406110b926393aa56f80a40eba40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>73fc7af87114b39712e6da79b0a377eb</td>\n",
       "      <td>esporte_lazer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-18 00:00:00</td>\n",
       "      <td>2018-01-18 21:46:59</td>\n",
       "      <td>41dcb106f807e993532d446263290104</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-01-11 15:30:49</td>\n",
       "      <td>2018-01-11 15:47:59</td>\n",
       "      <td>2018-01-12 21:57:22</td>\n",
       "      <td>2018-01-17 18:42:41</td>\n",
       "      <td>2018-02-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>80e641a11e56f04c1ad469d5645fdfde</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>a548910a1c6147796b98fdf73dbeba33</td>\n",
       "      <td>informatica_acessorios</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-10 00:00:00</td>\n",
       "      <td>2018-03-11 03:05:13</td>\n",
       "      <td>8a2e7ef9053dea531e4dc76bd6d853e6</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-28 12:25:19</td>\n",
       "      <td>2018-02-28 12:48:39</td>\n",
       "      <td>2018-03-02 19:08:15</td>\n",
       "      <td>2018-03-09 23:17:20</td>\n",
       "      <td>2018-03-14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>228ce5500dc1d8e020d8d1322874b6f0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>\n",
       "      <td>informatica_acessorios</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-17 00:00:00</td>\n",
       "      <td>2018-02-18 14:36:24</td>\n",
       "      <td>e226dfed6544df5b7b87a48208690feb</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-03 09:56:22</td>\n",
       "      <td>2018-02-03 10:33:41</td>\n",
       "      <td>2018-02-06 16:18:28</td>\n",
       "      <td>2018-02-16 17:28:48</td>\n",
       "      <td>2018-03-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>658677c97b385a9be170737859d3511b</td>\n",
       "      <td>ferramentas_jardim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>2017-04-21 00:00:00</td>\n",
       "      <td>2017-04-21 22:02:06</td>\n",
       "      <td>de6dff97e5f1ba84a3cd9a3bc97df5f6</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-04-09 17:41:13</td>\n",
       "      <td>2017-04-09 17:55:19</td>\n",
       "      <td>2017-04-10 14:24:47</td>\n",
       "      <td>2017-04-20 09:08:35</td>\n",
       "      <td>2017-05-10 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>esporte_lazer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ParabÃ©ns lojas lannister adorei comprar pela I...</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>2018-03-02 10:26:53</td>\n",
       "      <td>5986b333ca0d44534a156a52a8e33a83</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-10 10:59:03</td>\n",
       "      <td>2018-02-10 15:48:21</td>\n",
       "      <td>2018-02-15 19:36:14</td>\n",
       "      <td>2018-02-28 16:33:35</td>\n",
       "      <td>2018-03-09 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                         review_id  length_review  review_score  \\\n",
       "0           0  7bc2406110b926393aa56f80a40eba40              0             4   \n",
       "1           1  80e641a11e56f04c1ad469d5645fdfde              0             5   \n",
       "2           2  228ce5500dc1d8e020d8d1322874b6f0              0             5   \n",
       "3           3  e64fb393e7b32834bb789ff8bb30750e             37             5   \n",
       "4           4  f7c4243c7fe1938f181bec41a392bdeb            100             5   \n",
       "\n",
       "                           order_id   product_category_name  \\\n",
       "0  73fc7af87114b39712e6da79b0a377eb           esporte_lazer   \n",
       "1  a548910a1c6147796b98fdf73dbeba33  informatica_acessorios   \n",
       "2  f9e4b658b201a9f2ecdecbb34bed034b  informatica_acessorios   \n",
       "3  658677c97b385a9be170737859d3511b      ferramentas_jardim   \n",
       "4  8e6bfb81e283fa7e4f11123a3fb894f1           esporte_lazer   \n",
       "\n",
       "  review_comment_title                             review_comment_message  \\\n",
       "0                  NaN                                                NaN   \n",
       "1                  NaN                                                NaN   \n",
       "2                  NaN                                                NaN   \n",
       "3                  NaN              Recebi bem antes do prazo estipulado.   \n",
       "4                  NaN  ParabÃ©ns lojas lannister adorei comprar pela I...   \n",
       "\n",
       "  review_creation_date review_answer_timestamp  \\\n",
       "0  2018-01-18 00:00:00     2018-01-18 21:46:59   \n",
       "1  2018-03-10 00:00:00     2018-03-11 03:05:13   \n",
       "2  2018-02-17 00:00:00     2018-02-18 14:36:24   \n",
       "3  2017-04-21 00:00:00     2017-04-21 22:02:06   \n",
       "4  2018-03-01 00:00:00     2018-03-02 10:26:53   \n",
       "\n",
       "                        customer_id order_status order_purchase_timestamp  \\\n",
       "0  41dcb106f807e993532d446263290104    delivered      2018-01-11 15:30:49   \n",
       "1  8a2e7ef9053dea531e4dc76bd6d853e6    delivered      2018-02-28 12:25:19   \n",
       "2  e226dfed6544df5b7b87a48208690feb    delivered      2018-02-03 09:56:22   \n",
       "3  de6dff97e5f1ba84a3cd9a3bc97df5f6    delivered      2017-04-09 17:41:13   \n",
       "4  5986b333ca0d44534a156a52a8e33a83    delivered      2018-02-10 10:59:03   \n",
       "\n",
       "     order_approved_at order_delivered_carrier_date  \\\n",
       "0  2018-01-11 15:47:59          2018-01-12 21:57:22   \n",
       "1  2018-02-28 12:48:39          2018-03-02 19:08:15   \n",
       "2  2018-02-03 10:33:41          2018-02-06 16:18:28   \n",
       "3  2017-04-09 17:55:19          2017-04-10 14:24:47   \n",
       "4  2018-02-10 15:48:21          2018-02-15 19:36:14   \n",
       "\n",
       "  order_delivered_customer_date order_estimated_delivery_date  \n",
       "0           2018-01-17 18:42:41           2018-02-02 00:00:00  \n",
       "1           2018-03-09 23:17:20           2018-03-14 00:00:00  \n",
       "2           2018-02-16 17:28:48           2018-03-09 00:00:00  \n",
       "3           2017-04-20 09:08:35           2017-05-10 00:00:00  \n",
       "4           2018-02-28 16:33:35           2018-03-09 00:00:00  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q unidecode\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ml_olist_nlp_reviews.csv\"\n",
    "df = pd.read_csv(url, low_memory = False)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98657, 17)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question: Analyse the reviews to understand what could be the causes of the bad review scores** â“\n",
    "\n",
    "This challenge is not as guided as the previous ones. But here are some questions to ask yourself:\n",
    "\n",
    "- Are all the reviews relevant ? \n",
    "- What about combining the title and the body of a review ?\n",
    "- What cleaning operations would you apply to the reviews ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "delete_begin"
    ]
   },
   "outputs": [],
   "source": [
    "# Customers could review an order before receiving it...\n",
    "# We should consider reviews written only after receiving the order\n",
    "\n",
    "df = df[(df['review_creation_date'] >= df['order_delivered_customer_date'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73fc7af87114b39712e6da79b0a377eb</td>\n",
       "      <td>esporte_lazer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a548910a1c6147796b98fdf73dbeba33</td>\n",
       "      <td>informatica_acessorios</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>\n",
       "      <td>informatica_acessorios</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>658677c97b385a9be170737859d3511b</td>\n",
       "      <td>ferramentas_jardim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>esporte_lazer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ParabÃ©ns lojas lannister adorei comprar pela I...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id   product_category_name  \\\n",
       "0  73fc7af87114b39712e6da79b0a377eb           esporte_lazer   \n",
       "1  a548910a1c6147796b98fdf73dbeba33  informatica_acessorios   \n",
       "2  f9e4b658b201a9f2ecdecbb34bed034b  informatica_acessorios   \n",
       "3  658677c97b385a9be170737859d3511b      ferramentas_jardim   \n",
       "4  8e6bfb81e283fa7e4f11123a3fb894f1           esporte_lazer   \n",
       "\n",
       "  review_comment_title                             review_comment_message  \\\n",
       "0                  NaN                                                NaN   \n",
       "1                  NaN                                                NaN   \n",
       "2                  NaN                                                NaN   \n",
       "3                  NaN              Recebi bem antes do prazo estipulado.   \n",
       "4                  NaN  ParabÃ©ns lojas lannister adorei comprar pela I...   \n",
       "\n",
       "   review_score  \n",
       "0             4  \n",
       "1             5  \n",
       "2             5  \n",
       "3             5  \n",
       "4             5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only text columns and review score\n",
    "df = df[['order_id','product_category_name','review_comment_title','review_comment_message','review_score']]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_score</th>\n",
       "      <th>title_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b9bf720beb4ab3728760088589c62129</td>\n",
       "      <td>eletroportateis</td>\n",
       "      <td>recomendo</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "      <td>4</td>\n",
       "      <td>recomendo aparelho eficiente. no site a marca ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>e51478e7e277a83743b6f9991dbfa3fb</td>\n",
       "      <td>informatica_acessorios</td>\n",
       "      <td>Super recomendo</td>\n",
       "      <td>Vendedor confiÃ¡vel, produto ok e entrega antes...</td>\n",
       "      <td>5</td>\n",
       "      <td>Super recomendo Vendedor confiÃ¡vel, produto ok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4fc44d78867142c627497b60a7e0228a</td>\n",
       "      <td>beleza_saude</td>\n",
       "      <td>Ã“timo</td>\n",
       "      <td>Loja nota 10</td>\n",
       "      <td>5</td>\n",
       "      <td>Ã“timo Loja nota 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37e7875cdce5a9e5b3a692971f370151</td>\n",
       "      <td>esporte_lazer</td>\n",
       "      <td>Muito bom.</td>\n",
       "      <td>Recebi exatamente o que esperava. As demais en...</td>\n",
       "      <td>4</td>\n",
       "      <td>Muito bom. Recebi exatamente o que esperava. A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>e029f708df3cc108b3264558771605c6</td>\n",
       "      <td>pet_shop</td>\n",
       "      <td>Bom</td>\n",
       "      <td>Recomendo ,</td>\n",
       "      <td>5</td>\n",
       "      <td>Bom Recomendo ,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            order_id   product_category_name  \\\n",
       "9   b9bf720beb4ab3728760088589c62129         eletroportateis   \n",
       "15  e51478e7e277a83743b6f9991dbfa3fb  informatica_acessorios   \n",
       "22  4fc44d78867142c627497b60a7e0228a            beleza_saude   \n",
       "36  37e7875cdce5a9e5b3a692971f370151           esporte_lazer   \n",
       "38  e029f708df3cc108b3264558771605c6                pet_shop   \n",
       "\n",
       "   review_comment_title                             review_comment_message  \\\n",
       "9             recomendo  aparelho eficiente. no site a marca do aparelh...   \n",
       "15      Super recomendo  Vendedor confiÃ¡vel, produto ok e entrega antes...   \n",
       "22                Ã“timo                                       Loja nota 10   \n",
       "36           Muito bom.  Recebi exatamente o que esperava. As demais en...   \n",
       "38                  Bom                                        Recomendo ,   \n",
       "\n",
       "    review_score                                      title_comment  \n",
       "9              4  recomendo aparelho eficiente. no site a marca ...  \n",
       "15             5  Super recomendo Vendedor confiÃ¡vel, produto ok...  \n",
       "22             5                                 Ã“timo Loja nota 10  \n",
       "36             4  Muito bom. Recebi exatamente o que esperava. A...  \n",
       "38             5                                    Bom Recomendo ,  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine review title and review message\n",
    "df = df.dropna(subset=['review_comment_title','review_comment_message'])\n",
    "df['title_comment'] = df[\"review_comment_title\"].fillna('') + \" \" \\\n",
    "            + df['review_comment_message'].fillna('')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/delphine/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/home/delphine/nltk_data'\n    - '/home/delphine/.pyenv/versions/3.10.6/envs/lewagon/nltk_data'\n    - '/home/delphine/.pyenv/versions/3.10.6/envs/lewagon/share/nltk_data'\n    - '/home/delphine/.pyenv/versions/3.10.6/envs/lewagon/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - '/home/delphine/nltk_data'\n    - '/home/delphine/.pyenv/versions/3.10.6/envs/lewagon/nltk_data'\n    - '/home/delphine/.pyenv/versions/3.10.6/envs/lewagon/share/nltk_data'\n    - '/home/delphine/.pyenv/versions/3.10.6/envs/lewagon/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m     without_stopwords \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words_only \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m stop_words] \u001b[38;5;66;03m# Remove Stop Words\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(without_stopwords)\n\u001b[0;32m---> 30\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle_comment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4332\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/apply.py:1088\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/apply.py:1143\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1143\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1146\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn [8], line 24\u001b[0m, in \u001b[0;36mclean\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     20\u001b[0m tokenized \u001b[38;5;241m=\u001b[39m word_tokenize(unaccented_string) \u001b[38;5;66;03m# Tokenize\u001b[39;00m\n\u001b[1;32m     22\u001b[0m words_only \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokenized \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39misalpha()] \u001b[38;5;66;03m# Remove numbers\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m stop_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mstopwords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mportuguese\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;66;03m# Make stopword list\u001b[39;00m\n\u001b[1;32m     26\u001b[0m without_stopwords \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words_only \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m stop_words] \u001b[38;5;66;03m# Remove Stop Words\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(without_stopwords)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/home/delphine/nltk_data'\n    - '/home/delphine/.pyenv/versions/3.10.6/envs/lewagon/nltk_data'\n    - '/home/delphine/.pyenv/versions/3.10.6/envs/lewagon/share/nltk_data'\n    - '/home/delphine/.pyenv/versions/3.10.6/envs/lewagon/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Cleaning text\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import unidecode\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "def clean (text):\n",
    "\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, ' ') # Remove Punctuation\n",
    "\n",
    "    lowercased = text.lower() # Lower Case\n",
    "\n",
    "    unaccented_string = unidecode.unidecode(lowercased) # remove accents\n",
    "\n",
    "    tokenized = word_tokenize(unaccented_string) # Tokenize\n",
    "\n",
    "    words_only = [word for word in tokenized if word.isalpha()] # Remove numbers\n",
    "\n",
    "    stop_words = set(stopwords.words('portuguese')) # Make stopword list\n",
    "\n",
    "    without_stopwords = [word for word in words_only if not word in stop_words] # Remove Stop Words\n",
    "\n",
    "    return \" \".join(without_stopwords)\n",
    "\n",
    "df['clean_text'] = df['title_comment'].apply(clean)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.59\n",
       "4    0.16\n",
       "1    0.14\n",
       "3    0.07\n",
       "2    0.04\n",
       "Name: review_score, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the review scores...\n",
    "# ... we have more than 25% of the orders with review scores <= 3\n",
    "round(df[\"review_score\"].value_counts(normalize = True),2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's focus on these bad scores\n",
    "df = df[df[\"review_score\"]<=3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order_id', 'product_category_name', 'review_comment_title',\n",
       "       'review_comment_message', 'review_score', 'title_comment',\n",
       "       'clean_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range = (2,2),\n",
    "                             min_df=0.01,\n",
    "                             max_df = 0.05).fit(df.clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ainda nao</th>\n",
       "      <th>antes prazo</th>\n",
       "      <th>ate agora</th>\n",
       "      <th>ate momento</th>\n",
       "      <th>bom produto</th>\n",
       "      <th>comprei dois</th>\n",
       "      <th>comprei duas</th>\n",
       "      <th>comprei produto</th>\n",
       "      <th>defeito produto</th>\n",
       "      <th>dentro prazo</th>\n",
       "      <th>...</th>\n",
       "      <th>produto errado</th>\n",
       "      <th>produto recebi</th>\n",
       "      <th>recebi apenas</th>\n",
       "      <th>recomendo produto</th>\n",
       "      <th>so chegou</th>\n",
       "      <th>so recebi</th>\n",
       "      <th>so veio</th>\n",
       "      <th>veio defeito</th>\n",
       "      <th>veio errado</th>\n",
       "      <th>veio faltando</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ainda nao  antes prazo  ate agora  ate momento  bom produto  comprei dois  \\\n",
       "0        0.0          0.0        0.0          0.0          0.0           0.0   \n",
       "1        0.0          0.0        0.0          0.0          0.0           0.0   \n",
       "2        0.0          0.0        0.0          0.0          0.0           0.0   \n",
       "3        0.0          0.0        1.0          0.0          0.0           0.0   \n",
       "4        0.0          0.0        0.0          0.0          0.0           0.0   \n",
       "\n",
       "   comprei duas  comprei produto  defeito produto  dentro prazo  ...  \\\n",
       "0           0.0              0.0              0.0           0.0  ...   \n",
       "1           0.0              0.0              0.0           0.0  ...   \n",
       "2           0.0              0.0              0.0           0.0  ...   \n",
       "3           0.0              0.0              0.0           0.0  ...   \n",
       "4           0.0              0.0              0.0           0.0  ...   \n",
       "\n",
       "   produto errado  produto recebi  recebi apenas  recomendo produto  \\\n",
       "0             0.0             0.0            0.0                0.0   \n",
       "1             0.0             0.0            0.0                0.0   \n",
       "2             0.0             1.0            0.0                0.0   \n",
       "3             0.0             0.0            0.0                0.0   \n",
       "4             0.0             0.0            0.0                0.0   \n",
       "\n",
       "   so chegou  so recebi  so veio  veio defeito  veio errado  veio faltando  \n",
       "0        0.0        0.0      0.0           0.0          0.0            0.0  \n",
       "1        0.0        0.0      0.0           0.0          0.0            0.0  \n",
       "2        0.0        0.0      0.0           0.0          0.0            0.0  \n",
       "3        0.0        0.0      0.0           0.0          0.0            0.0  \n",
       "4        0.0        0.0      0.0           0.0          0.0            0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = pd.DataFrame(vectorizer.transform(df.clean_text).toarray(),\n",
    "                       columns = vectorizer.get_feature_names_out())\n",
    "vectors.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ainda nao            59.953928\n",
       "antes prazo          28.395321\n",
       "ate agora            36.184216\n",
       "ate momento          27.592462\n",
       "bom produto          30.792640\n",
       "comprei dois         27.888606\n",
       "comprei duas         23.936694\n",
       "comprei produto      26.983175\n",
       "defeito produto      16.787267\n",
       "dentro prazo         25.096925\n",
       "entrar contato       19.739133\n",
       "entregue nao         16.662659\n",
       "errado comprei       15.477524\n",
       "gostei produto       18.347935\n",
       "nao chegou           33.166038\n",
       "nao consigo          25.319662\n",
       "nao entregue         56.795948\n",
       "nao funciona         41.455319\n",
       "nao gostei           41.958468\n",
       "nao obtive           17.076249\n",
       "nao veio             54.798881\n",
       "nota fiscal          45.393544\n",
       "outro produto        19.117803\n",
       "pessima qualidade    30.066578\n",
       "porem nao            20.680051\n",
       "produto bom          36.363439\n",
       "produto chegou       45.080361\n",
       "produto comprei      27.615916\n",
       "produto defeito      41.936776\n",
       "produto diferente    36.387852\n",
       "produto entregue     46.093263\n",
       "produto errado       66.594133\n",
       "produto recebi       18.369131\n",
       "recebi apenas        44.918221\n",
       "recomendo produto    36.332677\n",
       "so chegou            15.794987\n",
       "so recebi            41.678290\n",
       "so veio              20.048705\n",
       "veio defeito         26.859616\n",
       "veio errado          21.065567\n",
       "veio faltando        21.899988\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_tfidf = vectors.sum(axis = 0)\n",
    "sum_tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('produto recebi', 18.36913055412219),\n",
       " ('ate agora', 36.184216388958035),\n",
       " ('produto defeito', 41.93677588570452),\n",
       " ('ainda nao', 59.95392767842011),\n",
       " ('nao obtive', 17.076249075368263),\n",
       " ('recebi apenas', 44.91822070048678),\n",
       " ('produto errado', 66.59413315707422),\n",
       " ('veio defeito', 26.85961632946528),\n",
       " ('defeito produto', 16.787266729501095),\n",
       " ('produto chegou', 45.08036102140102),\n",
       " ('antes prazo', 28.395320981582028),\n",
       " ('pessima qualidade', 30.066577634144036),\n",
       " ('nao gostei', 41.95846774793043),\n",
       " ('produto diferente', 36.38785195017216),\n",
       " ('nao consigo', 25.31966216476006),\n",
       " ('produto entregue', 46.09326281613154),\n",
       " ('produto bom', 36.36343877398457),\n",
       " ('comprei produto', 26.983175449717525),\n",
       " ('bom produto', 30.79264033815669),\n",
       " ('so recebi', 41.67828991932885),\n",
       " ('errado comprei', 15.47752353172635),\n",
       " ('entrar contato', 19.739133325547165),\n",
       " ('ate momento', 27.59246168657807),\n",
       " ('nao chegou', 33.16603770360955),\n",
       " ('recomendo produto', 36.332676681785465),\n",
       " ('porem nao', 20.680050828926134),\n",
       " ('nao funciona', 41.45531914089406),\n",
       " ('so veio', 20.04870491362076),\n",
       " ('produto comprei', 27.615915917635764),\n",
       " ('comprei dois', 27.888605969877165),\n",
       " ('comprei duas', 23.93669442873664),\n",
       " ('veio errado', 21.065566552288917),\n",
       " ('nao veio', 54.79888075566172),\n",
       " ('nao entregue', 56.795947662676284),\n",
       " ('veio faltando', 21.899988117004252),\n",
       " ('nota fiscal', 45.39354367145548),\n",
       " ('gostei produto', 18.347934543158352),\n",
       " ('entregue nao', 16.662658976277758),\n",
       " ('so chegou', 15.794986843598654),\n",
       " ('dentro prazo', 25.096925374200623),\n",
       " ('outro produto', 19.117802822200392)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_list = [(word, sum_tfidf[word])\n",
    "              for word, idx in vectorizer.vocabulary_.items()]\n",
    "tfidf_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "delete_end"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('produto errado', 66.59413315707422),\n",
       " ('ainda nao', 59.95392767842011),\n",
       " ('nao entregue', 56.795947662676284),\n",
       " ('nao veio', 54.79888075566172),\n",
       " ('produto entregue', 46.09326281613154),\n",
       " ('nota fiscal', 45.39354367145548),\n",
       " ('produto chegou', 45.08036102140102),\n",
       " ('recebi apenas', 44.91822070048678),\n",
       " ('nao gostei', 41.95846774793043),\n",
       " ('produto defeito', 41.93677588570452),\n",
       " ('so recebi', 41.67828991932885),\n",
       " ('nao funciona', 41.45531914089406),\n",
       " ('produto diferente', 36.38785195017216),\n",
       " ('produto bom', 36.36343877398457),\n",
       " ('recomendo produto', 36.332676681785465),\n",
       " ('ate agora', 36.184216388958035),\n",
       " ('nao chegou', 33.16603770360955),\n",
       " ('bom produto', 30.79264033815669),\n",
       " ('pessima qualidade', 30.066577634144036),\n",
       " ('antes prazo', 28.395320981582028),\n",
       " ('comprei dois', 27.888605969877165),\n",
       " ('produto comprei', 27.615915917635764),\n",
       " ('ate momento', 27.59246168657807),\n",
       " ('comprei produto', 26.983175449717525),\n",
       " ('veio defeito', 26.85961632946528),\n",
       " ('nao consigo', 25.31966216476006),\n",
       " ('dentro prazo', 25.096925374200623),\n",
       " ('comprei duas', 23.93669442873664),\n",
       " ('veio faltando', 21.899988117004252),\n",
       " ('veio errado', 21.065566552288917),\n",
       " ('porem nao', 20.680050828926134),\n",
       " ('so veio', 20.04870491362076),\n",
       " ('entrar contato', 19.739133325547165),\n",
       " ('outro produto', 19.117802822200392),\n",
       " ('produto recebi', 18.36913055412219),\n",
       " ('gostei produto', 18.347934543158352),\n",
       " ('nao obtive', 17.076249075368263),\n",
       " ('defeito produto', 16.787266729501095),\n",
       " ('entregue nao', 16.662658976277758),\n",
       " ('so chegou', 15.794986843598654),\n",
       " ('errado comprei', 15.47752353172635)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_tfidf_list =sorted(tfidf_list, key = lambda x: x[1], reverse=True)\n",
    "sorted_tfidf_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‡§ðŸ‡· Some Brazilian expressions and their translations:\n",
    "\n",
    "- `producto errado` = wrong product\n",
    "- `ainda nao` = not yet\n",
    "- `nao entregue` = not delivered\n",
    "- `nao veio` = did not come\n",
    "- `nao gostei` = did not like it\n",
    "- `produto defeito` = defective product\n",
    "- `nao functiona` = not working\n",
    "- `produto diferente` = different product\n",
    "- `pessima qualidade` = poor quality\n",
    "- `veio defeito` = came defect\n",
    "- `veio faltando` = came missing\n",
    "- `veio errado` = came wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ Congratulations. Instead of reading 90K+ reviews, you were able to detect the main reasons of dissatisfactions on Olist.\n",
    "\n",
    "ðŸ’¾ Don't forget to `git add/commit/push`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
